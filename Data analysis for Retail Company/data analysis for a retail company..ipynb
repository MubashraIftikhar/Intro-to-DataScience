{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Load the given datasets into Pandas DataFrames. Inspect the datasets and perform the\n",
    "following:\n",
    "• Display the first few rows of each dataset.\n",
    "• Show the total number of rows and columns.\n",
    "• Check for missing values in each dataset and handle them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of customers dataset:\n",
      "   CustomerID  Age         City\n",
      "0           1   22     New York\n",
      "1           2   23  Los Angeles\n",
      "2           3   24      Chicago\n",
      "3           4   25      Houston\n",
      "4           5   26      Phoenix\n",
      "First few rows of sales dataset:\n",
      "   SaleID  CustomerID     Product  Amount\n",
      "0     101           1      Laptop     200\n",
      "1     102           2  Smartphone     500\n",
      "2     103           3      Tablet     800\n",
      "3     104           4  Headphones    1100\n",
      "4     105           5     Monitor    1400\n",
      "Customers dataset: 100 rows, 3 columns\n",
      "Sales dataset: 400 rows, 4 columns\n",
      "Missing values in customers dataset:\n",
      "CustomerID    0\n",
      "Age           0\n",
      "City          0\n",
      "dtype: int64\n",
      "Missing values in sales dataset:\n",
      "SaleID        0\n",
      "CustomerID    0\n",
      "Product       0\n",
      "Amount        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading \n",
    "customers = pd.read_csv('customers.csv')\n",
    "sales = pd.read_csv('sales.csv')\n",
    "\n",
    "#  To display the first few rows of each dataset\n",
    "print(\"First few rows of customers dataset:\")\n",
    "print(customers.head())\n",
    "\n",
    "print(\"First few rows of sales dataset:\")\n",
    "print(sales.head())\n",
    "\n",
    "# Show the total number of rows and columns\n",
    "print(f\"Customers dataset: {customers.shape[0]} rows, {customers.shape[1]} columns\")\n",
    "print(f\"Sales dataset: {sales.shape[0]} rows, {sales.shape[1]} columns\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in customers dataset:\")\n",
    "print(customers.isnull().sum())\n",
    "\n",
    "print(\"Missing values in sales dataset:\")\n",
    "print(sales.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "customers.fillna('Unknown', inplace=True)\n",
    "sales.fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Using the customers.csv file, convert its data into a Python dictionary. \n",
    "Use the dictionary to filter customers from a specific city.\n",
    "Repeat the operation using a DataFrame and compare the efficiency of both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers in New York (via dictionary): 20\n",
      "Time taken by dictionary method: 0.0016520023345947266 seconds\n",
      "Number of customers in New York (via DataFrame): 20\n",
      "Time taken by DataFrame method: 0.006726264953613281 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Convert to dictionary\n",
    "customers_dict = customers.to_dict(orient='records') \n",
    "\n",
    "city='New York'\n",
    "# Time the dictionary method\n",
    "start_time_dict = time.time() \n",
    "filtered_customers_dict = [customer for customer in customers_dict if customer['City'] == city] \n",
    "end_time_dict = time.time() \n",
    "time_dict = end_time_dict - start_time_dict \n",
    "\n",
    "# Time the DataFrame method\n",
    "start_time_df = time.time() \n",
    "filtered_customers_df = customers[customers['City'] == city] \n",
    "end_time_df = time.time() \n",
    "time_df = end_time_df - start_time_df \n",
    "\n",
    "# Output results\n",
    "print(f\"Number of customers in {city} (via dictionary): {len(filtered_customers_dict)}\") \n",
    "print(f\"Time taken by dictionary method: {time_dict} seconds\") \n",
    "print(f\"Number of customers in {city} (via DataFrame): {filtered_customers_df.shape[0]}\") \n",
    "print(f\"Time taken by DataFrame method: {time_df} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Identify duplicate rows, if any, in the datasets. Remove these duplicates to ensure clean data.\n",
    "After cleaning, verify that there are no duplicates left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in customers dataset: 0\n",
      "Duplicate rows in sales dataset: 0\n",
      "Duplicate rows in customers dataset after cleaning: 0\n",
      "Duplicate rows in sales dataset after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Identify duplicate rows\n",
    "duplicates_customers = customers.duplicated()\n",
    "duplicates_sales = sales.duplicated()\n",
    "\n",
    "print(f\"Duplicate rows in customers dataset: {duplicates_customers.sum()}\")\n",
    "print(f\"Duplicate rows in sales dataset: {duplicates_sales.sum()}\")\n",
    "\n",
    "# Removal\n",
    "customers.drop_duplicates(inplace=True)\n",
    "sales.drop_duplicates(inplace=True)\n",
    "\n",
    "# Verification\n",
    "print(f\"Duplicate rows in customers dataset after cleaning: {customers.duplicated().sum()}\")\n",
    "print(f\"Duplicate rows in sales dataset after cleaning: {sales.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Create a new column with a 10% discount.\n",
    "Group by product and calculate total sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of sales dataset after adding TotalAfterDiscount column:\n",
      "   SaleID  CustomerID     Product  Amount  TotalAfterDiscount\n",
      "0     101           1      Laptop     200               180.0\n",
      "1     102           2  Smartphone     500               450.0\n",
      "2     103           3      Tablet     800               720.0\n",
      "3     104           4  Headphones    1100               990.0\n",
      "4     105           5     Monitor    1400              1260.0\n",
      "Total sales by product after discount:\n",
      "      Product  TotalAfterDiscount\n",
      "0  Headphones             79200.0\n",
      "1      Laptop             14400.0\n",
      "2     Monitor            100800.0\n",
      "3  Smartphone             36000.0\n",
      "4      Tablet             57600.0\n"
     ]
    }
   ],
   "source": [
    "#New column after discount\n",
    "sales['TotalAfterDiscount'] = sales['Amount'] * 0.9\n",
    "\n",
    "# Step 2: Verification\n",
    "print(\"First few rows of sales dataset after adding TotalAfterDiscount column:\")\n",
    "print(sales.head())\n",
    "\n",
    "# Group the data by product\n",
    "grouped_sales = sales.groupby('Product')\n",
    "\n",
    "# Calculate the total sales for each product\n",
    "total_sales_by_product = grouped_sales['TotalAfterDiscount'].sum().reset_index()\n",
    "\n",
    "print(\"Total sales by product after discount:\")\n",
    "print(total_sales_by_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Filter customers aged 25 to 35.\n",
    "Analyze customers by city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          City  Number of Customers\n",
      "0      Houston                   11\n",
      "1      Phoenix                    8\n",
      "2      Chicago                    7\n",
      "3     New York                    7\n",
      "4  Los Angeles                    7\n"
     ]
    }
   ],
   "source": [
    "# Filter customers aged 25 to 35\n",
    "filtered_customers_age = customers[(customers['Age'] >= 25) & (customers['Age'] <= 35)]\n",
    "\n",
    "# Analyze number of customers by city\n",
    "customers_by_city = filtered_customers_age['City'].value_counts().reset_index()\n",
    "customers_by_city.columns = ['City', 'Number of Customers']\n",
    "print(customers_by_city)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "Merge customers.csv and sales.csv on CustomerID.\n",
    "Identify the city with the highest total sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City with highest total sales:\n",
      "City                  Phoenix\n",
      "TotalAfterDiscount     100800\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Merge datasets on CustomerID\n",
    "merged_data = pd.merge(customers, sales, on='CustomerID')\n",
    "\n",
    "# Step 1: Identify the city with the highest total sales\n",
    "city_sales = merged_data.groupby('City')['TotalAfterDiscount'].sum().reset_index()\n",
    "top_city = city_sales.loc[city_sales['TotalAfterDiscount'].idxmax()]\n",
    "\n",
    "print(\"City with highest total sales:\")\n",
    "print(top_city)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "Display unique values in the City and Product columns.\n",
    "Calculate the mean and median of the Amount column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cities: ['New York' 'Los Angeles' 'Chicago' 'Houston' 'Phoenix']\n",
      "Unique products: ['Laptop' 'Smartphone' 'Tablet' 'Headphones' 'Monitor']\n",
      "Mean amount: 800.0\n",
      "Median amount: 800.0\n"
     ]
    }
   ],
   "source": [
    "# Display unique values\n",
    "unique_cities = merged_data['City'].unique()\n",
    "unique_products = merged_data['Product'].unique()\n",
    "\n",
    "print(f\"Unique cities: {unique_cities}\")\n",
    "print(f\"Unique products: {unique_products}\")\n",
    "\n",
    "# Calculate mean and median of the Amount column\n",
    "mean_amount = merged_data['Amount'].mean()\n",
    "median_amount = merged_data['Amount'].median()\n",
    "\n",
    "print(f\"Mean amount: {mean_amount}\")\n",
    "print(f\"Median amount: {median_amount}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
